{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\asdsf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open('book.txt','r') as file:\n",
    "    text = file.read()\n",
    "    # print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " BlankLineTokenizer -- разделяет заданный текст на токены на основе пустых строк, то есть последовательных переносов строк. Каждый блок текста, разделенный пустой строкой, рассматривается как отдельный токен или единица."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\\nI first published the novella A Clockwork Orange in 1962, which ought to be far enough in the past for it to be erased from the world's literary memory. It refuses to be erased, however, and for this the film version of the book made by Stanley Kubrick may be held chiefly responsible. I should myself be glad to disown it for various reasons, but this is not permitted. I receive mail from students who try to write theses about it or requests from Japanese dramaturges to turn It into a sort of Noh play. It seems likely to survive, while other works of mine that I value more bite the dust. This is not an unusual experience for an artist. Rachmaninoff used to groan because he was known mainly for a Prelude in C Sharp Minor which he wrote as a boy, while the works of his maturity never got into the programmes. Kids cut their pianistic teeth on a Minuet in G which Beethoven composed only so that he could detest it. I have to go on living with A Clockwork Orange, and this means I have a sort of authorial duty to it. I have a very special duty to it in the United States, and I had better now explain what this duty is. Let me put the situation baldly. A Clockwork Orange has never been published entire in America. The book I wrote is divided into three sections of seven chapters each. Take out your pocket calculator and you will find that these add up to a total of twenty-one chapters. 21 is the symbol for human maturity, or used to be, since at 21 you got the vote and assumed adult responsibility. Whatever its symbology, the number 21 was the number I started out with. Novelists of my stamp are interested in what is called arithmology, meaning that number has to mean something in human terms when they handle it. The number of chapters is never entirely arbitrary. Just as a musical composer starts off with a vague image of bulk and duration, so a novelist begins with an image of length, and this image is expressed in the number of sections and the number of chapters in which the work will be disposed. Those twenty-one chapters were important to me.\\n\"]\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# dir(nltk.tokenize)\n",
    "blanklineTokenizer = nt.BlanklineTokenizer()\n",
    "print(blanklineTokenizer.tokenize(text))\n",
    "\n",
    "print(\"-----------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяет текст по слогам, но как-то каряво"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI ',\n",
       " 'first ',\n",
       " 'pub',\n",
       " 'lis',\n",
       " 'hed t',\n",
       " 'he ',\n",
       " 'no',\n",
       " 'vel',\n",
       " 'la',\n",
       " ' A C',\n",
       " 'lock',\n",
       " 'work',\n",
       " ' O',\n",
       " 'ran',\n",
       " 'ge',\n",
       " ' in 1962, w',\n",
       " 'hich',\n",
       " ' o',\n",
       " 'ught ',\n",
       " 'to ',\n",
       " 'be ',\n",
       " 'far',\n",
       " ' e',\n",
       " 'no',\n",
       " 'ugh',\n",
       " ' in t',\n",
       " 'he ',\n",
       " 'past ',\n",
       " 'for',\n",
       " ' it ',\n",
       " 'to ',\n",
       " 'be',\n",
       " ' e',\n",
       " 'ra',\n",
       " 'sed f',\n",
       " 'rom t',\n",
       " 'he ',\n",
       " \"world's \",\n",
       " 'li',\n",
       " 'te',\n",
       " 'ra',\n",
       " 'ry ',\n",
       " 'me',\n",
       " 'mo',\n",
       " 'ry.',\n",
       " ' It ',\n",
       " 're',\n",
       " 'fu',\n",
       " 'ses ',\n",
       " 'to ',\n",
       " 'be',\n",
       " ' e',\n",
       " 'ra',\n",
       " 'sed, ',\n",
       " 'ho',\n",
       " 'we',\n",
       " 'ver,',\n",
       " ' and ',\n",
       " 'for t',\n",
       " 'his t',\n",
       " 'he ',\n",
       " 'film ',\n",
       " 'ver',\n",
       " 'si',\n",
       " 'on',\n",
       " ' of t',\n",
       " 'he ',\n",
       " 'bo',\n",
       " 'ok ',\n",
       " 'ma',\n",
       " 'de ',\n",
       " 'by S',\n",
       " 'tan',\n",
       " 'le',\n",
       " 'y ',\n",
       " 'Kub',\n",
       " 'rick ',\n",
       " 'ma',\n",
       " 'y ',\n",
       " 'be ',\n",
       " 'held c',\n",
       " 'hi',\n",
       " 'ef',\n",
       " 'ly ',\n",
       " 'res',\n",
       " 'pon',\n",
       " 'sib',\n",
       " 'le.',\n",
       " ' I s',\n",
       " 'ho',\n",
       " 'uld ',\n",
       " 'my',\n",
       " 'self ',\n",
       " 'be g',\n",
       " 'lad ',\n",
       " 'to ',\n",
       " 'di',\n",
       " 'sown',\n",
       " ' it ',\n",
       " 'for ',\n",
       " 'va',\n",
       " 'ri',\n",
       " 'o',\n",
       " 'us ',\n",
       " 're',\n",
       " 'a',\n",
       " 'sons, ',\n",
       " 'but t',\n",
       " 'his',\n",
       " ' is ',\n",
       " 'not ',\n",
       " 'per',\n",
       " 'mit',\n",
       " 'ted.',\n",
       " ' I ',\n",
       " 're',\n",
       " 'ce',\n",
       " 'i',\n",
       " 've ',\n",
       " 'ma',\n",
       " 'il f',\n",
       " 'rom s',\n",
       " 'tu',\n",
       " 'dents w',\n",
       " 'ho t',\n",
       " 'ry ',\n",
       " 'to w',\n",
       " 'ri',\n",
       " 'te t',\n",
       " 'he',\n",
       " 'ses',\n",
       " ' a',\n",
       " 'bo',\n",
       " 'ut',\n",
       " ' it',\n",
       " ' or ',\n",
       " 're',\n",
       " 'qu',\n",
       " 'ests f',\n",
       " 'rom ',\n",
       " 'Ja',\n",
       " 'pa',\n",
       " 'ne',\n",
       " 'se d',\n",
       " 'ra',\n",
       " 'ma',\n",
       " 'tur',\n",
       " 'ges ',\n",
       " 'to ',\n",
       " 'turn',\n",
       " ' It',\n",
       " ' in',\n",
       " 'to',\n",
       " ' a ',\n",
       " 'sort',\n",
       " ' of ',\n",
       " 'Noh p',\n",
       " 'la',\n",
       " 'y.',\n",
       " ' It ',\n",
       " 'se',\n",
       " 'ems ',\n",
       " 'li',\n",
       " 'ke',\n",
       " 'ly ',\n",
       " 'to ',\n",
       " 'sur',\n",
       " 'vi',\n",
       " 've, w',\n",
       " 'hi',\n",
       " 'le',\n",
       " ' ot',\n",
       " 'her ',\n",
       " 'works',\n",
       " ' of ',\n",
       " 'mi',\n",
       " 'ne t',\n",
       " 'hat',\n",
       " ' I ',\n",
       " 'va',\n",
       " 'lu',\n",
       " 'e ',\n",
       " 'mo',\n",
       " 're ',\n",
       " 'bi',\n",
       " 'te t',\n",
       " 'he ',\n",
       " 'dust. T',\n",
       " 'his',\n",
       " ' is ',\n",
       " 'not',\n",
       " ' an',\n",
       " ' u',\n",
       " 'nu',\n",
       " 'su',\n",
       " 'al',\n",
       " ' ex',\n",
       " 'pe',\n",
       " 'ri',\n",
       " 'en',\n",
       " 'ce ',\n",
       " 'for',\n",
       " ' an',\n",
       " ' ar',\n",
       " 'tist. ',\n",
       " 'Rach',\n",
       " 'ma',\n",
       " 'ni',\n",
       " 'noff',\n",
       " ' u',\n",
       " 'sed ',\n",
       " 'to g',\n",
       " 'ro',\n",
       " 'an ',\n",
       " 'be',\n",
       " 'ca',\n",
       " 'u',\n",
       " 'se ',\n",
       " 'he ',\n",
       " 'was k',\n",
       " 'nown ',\n",
       " 'ma',\n",
       " 'in',\n",
       " 'ly ',\n",
       " 'for',\n",
       " ' a P',\n",
       " 're',\n",
       " 'lu',\n",
       " 'de',\n",
       " ' in C S',\n",
       " 'harp ',\n",
       " 'Mi',\n",
       " 'nor w',\n",
       " 'hich ',\n",
       " 'he w',\n",
       " 'ro',\n",
       " 'te',\n",
       " ' as',\n",
       " ' a ',\n",
       " 'bo',\n",
       " 'y, w',\n",
       " 'hi',\n",
       " 'le t',\n",
       " 'he ',\n",
       " 'works',\n",
       " ' of ',\n",
       " 'his ',\n",
       " 'ma',\n",
       " 'tu',\n",
       " 'ri',\n",
       " 'ty ',\n",
       " 'ne',\n",
       " 'ver ',\n",
       " 'got',\n",
       " ' in',\n",
       " 'to t',\n",
       " 'he p',\n",
       " 'rog',\n",
       " 'ram',\n",
       " 'mes. ',\n",
       " 'Kids ',\n",
       " 'cut t',\n",
       " 'he',\n",
       " 'ir ',\n",
       " 'pi',\n",
       " 'a',\n",
       " 'nis',\n",
       " 'tic ',\n",
       " 'te',\n",
       " 'eth',\n",
       " ' on',\n",
       " ' a ',\n",
       " 'Mi',\n",
       " 'nu',\n",
       " 'et',\n",
       " ' in G w',\n",
       " 'hich ',\n",
       " 'Be',\n",
       " 'et',\n",
       " 'ho',\n",
       " 'ven ',\n",
       " 'com',\n",
       " 'po',\n",
       " 'sed',\n",
       " ' on',\n",
       " 'ly ',\n",
       " 'so t',\n",
       " 'hat ',\n",
       " 'he ',\n",
       " 'co',\n",
       " 'uld ',\n",
       " 'de',\n",
       " 'test',\n",
       " ' it.',\n",
       " ' I ',\n",
       " 'ha',\n",
       " 've ',\n",
       " 'to ',\n",
       " 'go',\n",
       " ' on ',\n",
       " 'li',\n",
       " 'ving ',\n",
       " 'with',\n",
       " ' A C',\n",
       " 'lock',\n",
       " 'work',\n",
       " ' O',\n",
       " 'ran',\n",
       " 'ge,',\n",
       " ' and t',\n",
       " 'his ',\n",
       " 'me',\n",
       " 'ans',\n",
       " ' I ',\n",
       " 'ha',\n",
       " 've',\n",
       " ' a ',\n",
       " 'sort',\n",
       " ' of',\n",
       " ' a',\n",
       " 'ut',\n",
       " 'ho',\n",
       " 'ri',\n",
       " 'al ',\n",
       " 'du',\n",
       " 'ty ',\n",
       " 'to',\n",
       " ' it.',\n",
       " ' I ',\n",
       " 'ha',\n",
       " 've',\n",
       " ' a ',\n",
       " 've',\n",
       " 'ry s',\n",
       " 'pe',\n",
       " 'ci',\n",
       " 'al ',\n",
       " 'du',\n",
       " 'ty ',\n",
       " 'to',\n",
       " ' it',\n",
       " ' in t',\n",
       " 'he',\n",
       " ' U',\n",
       " 'ni',\n",
       " 'ted S',\n",
       " 'ta',\n",
       " 'tes,',\n",
       " ' and',\n",
       " ' I ',\n",
       " 'had ',\n",
       " 'bet',\n",
       " 'ter ',\n",
       " 'now',\n",
       " ' exp',\n",
       " 'la',\n",
       " 'in w',\n",
       " 'hat t',\n",
       " 'his ',\n",
       " 'du',\n",
       " 'ty',\n",
       " ' is. ',\n",
       " 'Let ',\n",
       " 'me ',\n",
       " 'put t',\n",
       " 'he ',\n",
       " 'si',\n",
       " 'tu',\n",
       " 'a',\n",
       " 'ti',\n",
       " 'on ',\n",
       " 'bald',\n",
       " 'ly.',\n",
       " ' A C',\n",
       " 'lock',\n",
       " 'work',\n",
       " ' O',\n",
       " 'ran',\n",
       " 'ge ',\n",
       " 'has ',\n",
       " 'ne',\n",
       " 'ver ',\n",
       " 'be',\n",
       " 'en ',\n",
       " 'pub',\n",
       " 'lis',\n",
       " 'hed',\n",
       " ' en',\n",
       " 'ti',\n",
       " 're',\n",
       " ' in',\n",
       " ' A',\n",
       " 'me',\n",
       " 'ri',\n",
       " 'ca. T',\n",
       " 'he ',\n",
       " 'bo',\n",
       " 'ok',\n",
       " ' I w',\n",
       " 'ro',\n",
       " 'te',\n",
       " ' is ',\n",
       " 'di',\n",
       " 'vi',\n",
       " 'ded',\n",
       " ' in',\n",
       " 'to th',\n",
       " 're',\n",
       " 'e ',\n",
       " 'sec',\n",
       " 'ti',\n",
       " 'ons',\n",
       " ' of ',\n",
       " 'se',\n",
       " 'ven c',\n",
       " 'hap',\n",
       " 'ters',\n",
       " ' e',\n",
       " 'ach. ',\n",
       " 'Ta',\n",
       " 'ke',\n",
       " ' o',\n",
       " 'ut',\n",
       " ' y',\n",
       " 'o',\n",
       " 'ur ',\n",
       " 'poc',\n",
       " 'ket ',\n",
       " 'cal',\n",
       " 'cu',\n",
       " 'la',\n",
       " 'tor',\n",
       " ' and',\n",
       " ' y',\n",
       " 'o',\n",
       " 'u ',\n",
       " 'will ',\n",
       " 'find t',\n",
       " 'hat t',\n",
       " 'he',\n",
       " 'se',\n",
       " ' add',\n",
       " ' up ',\n",
       " 'to',\n",
       " ' a ',\n",
       " 'to',\n",
       " 'tal',\n",
       " ' of t',\n",
       " 'wen',\n",
       " 'ty',\n",
       " '-o',\n",
       " 'ne c',\n",
       " 'hap',\n",
       " 'ters. 21',\n",
       " ' is t',\n",
       " 'he ',\n",
       " 'sym',\n",
       " 'bol ',\n",
       " 'for ',\n",
       " 'hu',\n",
       " 'man ',\n",
       " 'ma',\n",
       " 'tu',\n",
       " 'ri',\n",
       " 'ty,',\n",
       " ' or',\n",
       " ' u',\n",
       " 'sed ',\n",
       " 'to ',\n",
       " 'be, ',\n",
       " 'sin',\n",
       " 'ce',\n",
       " ' at 21',\n",
       " ' y',\n",
       " 'o',\n",
       " 'u ',\n",
       " 'got t',\n",
       " 'he ',\n",
       " 'vo',\n",
       " 'te',\n",
       " ' and',\n",
       " ' as',\n",
       " 'su',\n",
       " 'med',\n",
       " ' a',\n",
       " 'dult ',\n",
       " 'res',\n",
       " 'pon',\n",
       " 'si',\n",
       " 'bi',\n",
       " 'li',\n",
       " 'ty. W',\n",
       " 'ha',\n",
       " 'te',\n",
       " 'ver',\n",
       " ' its ',\n",
       " 'sym',\n",
       " 'bo',\n",
       " 'lo',\n",
       " 'gy, t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'ber 21 ',\n",
       " 'was t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'ber',\n",
       " ' I s',\n",
       " 'tar',\n",
       " 'ted',\n",
       " ' o',\n",
       " 'ut ',\n",
       " 'with. ',\n",
       " 'No',\n",
       " 've',\n",
       " 'lists',\n",
       " ' of ',\n",
       " 'my s',\n",
       " 'tamp',\n",
       " ' a',\n",
       " 're',\n",
       " ' in',\n",
       " 'te',\n",
       " 'res',\n",
       " 'ted',\n",
       " ' in w',\n",
       " 'hat',\n",
       " ' is ',\n",
       " 'cal',\n",
       " 'led',\n",
       " ' a',\n",
       " 'rith',\n",
       " 'mo',\n",
       " 'lo',\n",
       " 'gy, ',\n",
       " 'me',\n",
       " 'a',\n",
       " 'ning t',\n",
       " 'hat ',\n",
       " 'num',\n",
       " 'ber ',\n",
       " 'has ',\n",
       " 'to ',\n",
       " 'me',\n",
       " 'an ',\n",
       " 'so',\n",
       " 'met',\n",
       " 'hing',\n",
       " ' in ',\n",
       " 'hu',\n",
       " 'man ',\n",
       " 'terms w',\n",
       " 'hen t',\n",
       " 'he',\n",
       " 'y ',\n",
       " 'hand',\n",
       " 'le',\n",
       " ' it. T',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'ber',\n",
       " ' of c',\n",
       " 'hap',\n",
       " 'ters',\n",
       " ' is ',\n",
       " 'ne',\n",
       " 'ver',\n",
       " ' en',\n",
       " 'ti',\n",
       " 're',\n",
       " 'ly',\n",
       " ' ar',\n",
       " 'bit',\n",
       " 'ra',\n",
       " 'ry. ',\n",
       " 'Just',\n",
       " ' as',\n",
       " ' a ',\n",
       " 'mu',\n",
       " 'si',\n",
       " 'cal ',\n",
       " 'com',\n",
       " 'po',\n",
       " 'ser s',\n",
       " 'tarts',\n",
       " ' off ',\n",
       " 'with',\n",
       " ' a ',\n",
       " 'va',\n",
       " 'gu',\n",
       " 'e',\n",
       " ' i',\n",
       " 'ma',\n",
       " 'ge',\n",
       " ' of ',\n",
       " 'bulk',\n",
       " ' and ',\n",
       " 'du',\n",
       " 'ra',\n",
       " 'ti',\n",
       " 'on, ',\n",
       " 'so',\n",
       " ' a ',\n",
       " 'no',\n",
       " 've',\n",
       " 'list ',\n",
       " 'be',\n",
       " 'gins ',\n",
       " 'with',\n",
       " ' an',\n",
       " ' i',\n",
       " 'ma',\n",
       " 'ge',\n",
       " ' of ',\n",
       " 'length,',\n",
       " ' and t',\n",
       " 'his',\n",
       " ' i',\n",
       " 'ma',\n",
       " 'ge',\n",
       " ' is',\n",
       " ' exp',\n",
       " 'res',\n",
       " 'sed',\n",
       " ' in t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'ber',\n",
       " ' of ',\n",
       " 'sec',\n",
       " 'ti',\n",
       " 'ons',\n",
       " ' and t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'ber',\n",
       " ' of c',\n",
       " 'hap',\n",
       " 'ters',\n",
       " ' in w',\n",
       " 'hich t',\n",
       " 'he ',\n",
       " 'work ',\n",
       " 'will ',\n",
       " 'be ',\n",
       " 'dis',\n",
       " 'po',\n",
       " 'sed. T',\n",
       " 'ho',\n",
       " 'se t',\n",
       " 'wen',\n",
       " 'ty',\n",
       " '-o',\n",
       " 'ne c',\n",
       " 'hap',\n",
       " 'ters ',\n",
       " 'we',\n",
       " 're',\n",
       " ' im',\n",
       " 'por',\n",
       " 'tant ',\n",
       " 'to ',\n",
       " 'me.\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lst = nt.LegalitySyllableTokenizer(text, 'aieuoy', 0.00000000000000000001,)\n",
    "lst.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делает токены из предложений разделённых \\n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I first published the novella A Clockwork Orange in 1962, which ought to be far enough in the past for it to be erased from the world's literary memory. It refuses to be erased, \",\n",
       " ' however, and for this the film version of the book made by Stanley Kubrick may be held chiefly responsible. I should myself be glad to disown ',\n",
       " ' it for various reasons, but this is not permitted. I receive mail from students who try',\n",
       " ' to write theses about it or req']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.LineTokenizer()\n",
    "text_ex =  \"I first published the novella A Clockwork Orange in 1962, which ought to be far enough in the past for it to be erased from the world's literary memory. It refuses to be erased, \\n however, and for this the film version of the book made by Stanley Kubrick may be held chiefly responsible. I should myself be glad to disown \\n it for various reasons, but this is not permitted. I receive mail from students who try\\n to write theses about it or req\"\n",
    "\n",
    "tk.tokenize(text_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MWETokenizer делает токены из букв в слове"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'I',\n",
       " ' ',\n",
       " 'f',\n",
       " 'i',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 's',\n",
       " 'h',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " ' ',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'l',\n",
       " 'o',\n",
       " 'c',\n",
       " 'k',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'O',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " '1',\n",
       " '9',\n",
       " '6',\n",
       " '2',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " ' ',\n",
       " 'o',\n",
       " 'u',\n",
       " 'g',\n",
       " 'h',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 'r',\n",
       " ' ',\n",
       " 'e',\n",
       " 'n',\n",
       " 'o',\n",
       " 'u',\n",
       " 'g',\n",
       " 'h',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " \"'\",\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'y',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'f',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " ',',\n",
       " ' ',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'i',\n",
       " 'l',\n",
       " 'm',\n",
       " ' ',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'y',\n",
       " ' ',\n",
       " 'S',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'K',\n",
       " 'u',\n",
       " 'b',\n",
       " 'r',\n",
       " 'i',\n",
       " 'c',\n",
       " 'k',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'i',\n",
       " 'e',\n",
       " 'f',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'm',\n",
       " 'y',\n",
       " 's',\n",
       " 'e',\n",
       " 'l',\n",
       " 'f',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'g',\n",
       " 'l',\n",
       " 'a',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'w',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'v',\n",
       " 'a',\n",
       " 'r',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'c',\n",
       " 'e',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'd',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'y',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'w',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 's',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'q',\n",
       " 'u',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'J',\n",
       " 'a',\n",
       " 'p',\n",
       " 'a',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'r',\n",
       " 'a',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'g',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'n',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'N',\n",
       " 'o',\n",
       " 'h',\n",
       " ' ',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'y',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'e',\n",
       " 'm',\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 's',\n",
       " 'u',\n",
       " 'r',\n",
       " 'v',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'm',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'v',\n",
       " 'a',\n",
       " 'l',\n",
       " 'u',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'i',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'u',\n",
       " 's',\n",
       " 't',\n",
       " '.',\n",
       " ' ',\n",
       " 'T',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 'u',\n",
       " 's',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'e',\n",
       " 'x',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " '.',\n",
       " ' ',\n",
       " 'R',\n",
       " 'a',\n",
       " 'c',\n",
       " 'h',\n",
       " 'm',\n",
       " 'a',\n",
       " 'n',\n",
       " 'i',\n",
       " 'n',\n",
       " 'o',\n",
       " 'f',\n",
       " 'f',\n",
       " ' ',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'r',\n",
       " 'o',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " 'c',\n",
       " 'a',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'k',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " 'n',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'P',\n",
       " 'r',\n",
       " 'e',\n",
       " 'l',\n",
       " 'u',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'C',\n",
       " ' ',\n",
       " 'S',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'p',\n",
       " ' ',\n",
       " 'M',\n",
       " 'i',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'r',\n",
       " 'o',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 'y',\n",
       " ',',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'g',\n",
       " 'r',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " '.',\n",
       " ' ',\n",
       " 'K',\n",
       " 'i',\n",
       " 'd',\n",
       " 's',\n",
       " ' ',\n",
       " 'c',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'i',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'M',\n",
       " 'i',\n",
       " 'n',\n",
       " 'u',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'G',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " ' ',\n",
       " 'B',\n",
       " 'e',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'p',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'd',\n",
       " 'e',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'v',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'A',\n",
       " ' ',\n",
       " 'C',\n",
       " 'l',\n",
       " 'o',\n",
       " 'c',\n",
       " 'k',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'O',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'g',\n",
       " 'e',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 'a',\n",
       " 'n',\n",
       " 's',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NWEtk = nt.MWETokenizer()\n",
    "\n",
    "NWEtk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTKWordTokenizer делает токены из отдельных слов, и знаков препинания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'literary',\n",
       " 'memory.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " 'chapters.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed.',\n",
       " 'Those',\n",
       " 'twenty-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.NLTKWordTokenizer()\n",
    "\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PunktSentenceTokenizer -- делает токены из предложений разделённые точкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nI first published the novella A Clockwork Orange in 1962, which ought to be far enough in the past for it to be erased from the world's literary memory.\",\n",
       " 'It refuses to be erased, however, and for this the film version of the book made by Stanley Kubrick may be held chiefly responsible.',\n",
       " 'I should myself be glad to disown it for various reasons, but this is not permitted.',\n",
       " 'I receive mail from students who try to write theses about it or requests from Japanese dramaturges to turn It into a sort of Noh play.',\n",
       " 'It seems likely to survive, while other works of mine that I value more bite the dust.',\n",
       " 'This is not an unusual experience for an artist.',\n",
       " 'Rachmaninoff used to groan because he was known mainly for a Prelude in C Sharp Minor which he wrote as a boy, while the works of his maturity never got into the programmes.',\n",
       " 'Kids cut their pianistic teeth on a Minuet in G which Beethoven composed only so that he could detest it.',\n",
       " 'I have to go on living with A Clockwork Orange, and this means I have a sort of authorial duty to it.',\n",
       " 'I have a very special duty to it in the United States, and I had better now explain what this duty is.',\n",
       " 'Let me put the situation baldly.',\n",
       " 'A Clockwork Orange has never been published entire in America.',\n",
       " 'The book I wrote is divided into three sections of seven chapters each.',\n",
       " 'Take out your pocket calculator and you will find that these add up to a total of twenty-one chapters.',\n",
       " '21 is the symbol for human maturity, or used to be, since at 21 you got the vote and assumed adult responsibility.',\n",
       " 'Whatever its symbology, the number 21 was the number I started out with.',\n",
       " 'Novelists of my stamp are interested in what is called arithmology, meaning that number has to mean something in human terms when they handle it.',\n",
       " 'The number of chapters is never entirely arbitrary.',\n",
       " 'Just as a musical composer starts off with a vague image of bulk and duration, so a novelist begins with an image of length, and this image is expressed in the number of sections and the number of chapters in which the work will be disposed.',\n",
       " 'Those twenty-one chapters were important to me.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.PunktSentenceTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegexpTokenizer -- разбивает текст на регулярные выражения с помощью паттерна, который передаётся как параметр в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'literary',\n",
       " 'memory',\n",
       " '.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted',\n",
       " '.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play',\n",
       " '.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist',\n",
       " '.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes',\n",
       " '.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is',\n",
       " '.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly',\n",
       " '.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America',\n",
       " '.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each',\n",
       " '.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty',\n",
       " '-one',\n",
       " 'chapters',\n",
       " '.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility',\n",
       " '.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with',\n",
       " '.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it',\n",
       " '.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed',\n",
       " '.',\n",
       " 'Those',\n",
       " 'twenty',\n",
       " '-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "tk.tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не понятно что делает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the /Users/asdsf/repp file!\nUse software specific configuration parameters or set the REPP_TOKENIZER environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asdsf\\major-IT-musled\\tokerize\\tokenize.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tk \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39;49mReppTokenizer(\u001b[39m'\u001b[39;49m\u001b[39m/Users/asdsf/repp\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tk\u001b[39m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tokenize\\repp.py:55\u001b[0m, in \u001b[0;36mReppTokenizer.__init__\u001b[1;34m(self, repp_dir, encoding)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, repp_dir, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepp_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_repptokenizer(repp_dir)\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Set a directory to store the temporary files.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworking_dir \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mgettempdir()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tokenize\\repp.py:145\u001b[0m, in \u001b[0;36mReppTokenizer.find_repptokenizer\u001b[1;34m(self, repp_dirname)\u001b[0m\n\u001b[0;32m    143\u001b[0m     _repp_dir \u001b[39m=\u001b[39m repp_dirname\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Try to find path to REPP directory in environment variables.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     _repp_dir \u001b[39m=\u001b[39m find_dir(repp_dirname, env_vars\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mREPP_TOKENIZER\u001b[39;49m\u001b[39m\"\u001b[39;49m,))\n\u001b[0;32m    146\u001b[0m \u001b[39m# Checks for the REPP binary and erg/repp.set config file.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(_repp_dir \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/src/repp\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:634\u001b[0m, in \u001b[0;36mfind_dir\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_dir\u001b[39m(\n\u001b[0;32m    632\u001b[0m     filename, env_vars\u001b[39m=\u001b[39m(), searchpath\u001b[39m=\u001b[39m(), file_names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    633\u001b[0m ):\n\u001b[1;32m--> 634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    635\u001b[0m         find_file_iter(\n\u001b[0;32m    636\u001b[0m             filename, env_vars, searchpath, file_names, url, verbose, finding_dir\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    637\u001b[0m         )\n\u001b[0;32m    638\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:620\u001b[0m, in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    618\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  For more information on \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    <\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[1;32m--> 620\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the /Users/asdsf/repp file!\nUse software specific configuration parameters or set the REPP_TOKENIZER environment variable.\n==========================================================================="
     ]
    }
   ],
   "source": [
    "tk = nt.ReppTokenizer('/Users/asdsf/repp')\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SExprTokenizer -- разделяет строку на токеты, которые закрыты в скобочки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nI first published the novella A Clockwork Orange in 1962, which ought to be far enough in the past for it to be erased from the world's literary memory. It refuses to be erased, however, and for this the film version of the book made by Stanley Kubrick may be held chiefly responsible. I should myself be glad to disown it for various reasons, but this is not permitted. I receive mail from students who try to write theses about it or requests from Japanese dramaturges to turn It into a sort of Noh play. It seems likely to survive, while other works of mine that I value more bite the dust. This is not an unusual experience for an artist. Rachmaninoff used to groan because he was known mainly for a Prelude in C Sharp Minor which he wrote as a boy, while the works of his maturity never got into the programmes. Kids cut their pianistic teeth on a Minuet in G which Beethoven composed only so that he could detest it. I have to go on living with A Clockwork Orange, and this means I have a sort of authorial duty to it. I have a very special duty to it in the United States, and I had better now explain what this duty is. Let me put the situation baldly. A Clockwork Orange has never been published entire in America. The book I wrote is divided into three sections of seven chapters each. Take out your pocket calculator and you will find that these add up to a total of twenty-one chapters. 21 is the symbol for human maturity, or used to be, since at 21 you got the vote and assumed adult responsibility. Whatever its symbology, the number 21 was the number I started out with. Novelists of my stamp are interested in what is called arithmology, meaning that number has to mean something in human terms when they handle it. The number of chapters is never entirely arbitrary. Just as a musical composer starts off with a vague image of bulk and duration, so a novelist begins with an image of length, and this image is expressed in the number of sections and the number of chapters in which the work will be disposed. Those twenty-one chapters were important to me.\\n\"]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.SExprTokenizer(\"()\")\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это токенайзер разделяет по пробелам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962,',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " \"world's\",\n",
       " 'literary',\n",
       " 'memory.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased,',\n",
       " 'however,',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons,',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive,',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy,',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange,',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " 'chapters.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity,',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be,',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology,',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology,',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration,',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length,',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed.',\n",
       " 'Those',\n",
       " 'twenty-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me.\\n']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.SpaceTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Китайский какой-то использовать = кринж "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdsf\\AppData\\Local\\Temp\\ipykernel_13344\\2851082851.py:1: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPTokenizer\u001b[0m instead.'\n",
      "  tk = nt.StanfordSegmenter()\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\n  NLTK was unable to find stanford-segmenter.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-segmenter.jar, see:\n    <https://nlp.stanford.edu/software>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asdsf\\major-IT-musled\\tokerize\\tokenize.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tk \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39;49mStanfordSegmenter()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tk\u001b[39m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tokenize\\stanford_segmenter.py:84\u001b[0m, in \u001b[0;36mStanfordSegmenter.__init__\u001b[1;34m(self, path_to_jar, path_to_slf4j, java_class, path_to_model, path_to_dict, path_to_sihan_corpora_dict, sihan_post_processing, keep_whitespaces, encoding, options, verbose, java_options)\u001b[0m\n\u001b[0;32m     73\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     74\u001b[0m     \u001b[39mstr\u001b[39m(\n\u001b[0;32m     75\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mThe StanfordTokenizer will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m---> 84\u001b[0m stanford_segmenter \u001b[39m=\u001b[39m find_jar(\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_JAR,\n\u001b[0;32m     86\u001b[0m     path_to_jar,\n\u001b[0;32m     87\u001b[0m     env_vars\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mSTANFORD_SEGMENTER\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m     88\u001b[0m     searchpath\u001b[39m=\u001b[39;49m(),\n\u001b[0;32m     89\u001b[0m     url\u001b[39m=\u001b[39;49m_stanford_url,\n\u001b[0;32m     90\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m     91\u001b[0m )\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m path_to_slf4j \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     slf4j \u001b[39m=\u001b[39m find_jar(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mslf4j-api.jar\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     95\u001b[0m         path_to_slf4j,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    100\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:833\u001b[0m, in \u001b[0;36mfind_jar\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_jar\u001b[39m(\n\u001b[0;32m    825\u001b[0m     name_pattern,\n\u001b[0;32m    826\u001b[0m     path_to_jar\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m     is_regex\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    832\u001b[0m ):\n\u001b[1;32m--> 833\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    834\u001b[0m         find_jar_iter(\n\u001b[0;32m    835\u001b[0m             name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex\n\u001b[0;32m    836\u001b[0m         )\n\u001b[0;32m    837\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:821\u001b[0m, in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    816\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  For more information, on \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    <\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m         name_pattern,\n\u001b[0;32m    818\u001b[0m         url,\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    820\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[1;32m--> 821\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\n  NLTK was unable to find stanford-segmenter.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-segmenter.jar, see:\n    <https://nlp.stanford.edu/software>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "tk = nt.StanfordSegmenter()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyllableTokenizer -- ещё один токенайзер, который разделяет по слогам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdsf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: '\n",
      "'\n",
      "  warnings.warn(\n",
      "C:\\Users\\asdsf\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\tokenize\\sonority_sequencing.py:102: UserWarning: Character not defined in sonority_hierarchy, assigning as vowel: ' '\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nI',\n",
       " ' ',\n",
       " 'firs',\n",
       " 't ',\n",
       " 'pu',\n",
       " 'blis',\n",
       " 'he',\n",
       " 'd t',\n",
       " 'he ',\n",
       " 'no',\n",
       " 'vel',\n",
       " 'la A',\n",
       " ' ',\n",
       " 'Cloc',\n",
       " 'kwor',\n",
       " 'k O',\n",
       " 'ran',\n",
       " 'ge ',\n",
       " 'i',\n",
       " 'n 1',\n",
       " '9',\n",
       " '6',\n",
       " '2',\n",
       " '',\n",
       " ',',\n",
       " ' w',\n",
       " 'hic',\n",
       " 'h o',\n",
       " 'ugh',\n",
       " 't ',\n",
       " 'to ',\n",
       " 'be ',\n",
       " 'fa',\n",
       " 'r e',\n",
       " 'noug',\n",
       " 'h i',\n",
       " 'n t',\n",
       " 'he ',\n",
       " 'pas',\n",
       " 't ',\n",
       " 'fo',\n",
       " 'r i',\n",
       " 't ',\n",
       " 'to ',\n",
       " 'be ',\n",
       " 'e',\n",
       " 'ra',\n",
       " 'se',\n",
       " 'd ',\n",
       " 'fro',\n",
       " 'm t',\n",
       " 'he ',\n",
       " 'world',\n",
       " \"'\",\n",
       " 's ',\n",
       " 'li',\n",
       " 'te',\n",
       " 'ra',\n",
       " 'ry ',\n",
       " 'me',\n",
       " 'mo',\n",
       " 'ry',\n",
       " '.',\n",
       " ' I',\n",
       " 't ',\n",
       " 're',\n",
       " 'fu',\n",
       " 'se',\n",
       " 's ',\n",
       " 'to ',\n",
       " 'be ',\n",
       " 'e',\n",
       " 'ra',\n",
       " 'sed',\n",
       " ',',\n",
       " ' ',\n",
       " 'ho',\n",
       " 'we',\n",
       " 'ver',\n",
       " ',',\n",
       " ' an',\n",
       " 'd ',\n",
       " 'fo',\n",
       " 'r t',\n",
       " 'hi',\n",
       " 's t',\n",
       " 'he ',\n",
       " 'fil',\n",
       " 'm ',\n",
       " 'ver',\n",
       " 'sio',\n",
       " 'n o',\n",
       " 'f t',\n",
       " 'he ',\n",
       " 'boo',\n",
       " 'k ',\n",
       " 'ma',\n",
       " 'de ',\n",
       " 'by S',\n",
       " 'tan',\n",
       " 'ley',\n",
       " ' ',\n",
       " 'Ku',\n",
       " 'bric',\n",
       " 'k ',\n",
       " 'may',\n",
       " ' ',\n",
       " 'be ',\n",
       " 'hel',\n",
       " 'd c',\n",
       " 'hie',\n",
       " 'fly ',\n",
       " 'res',\n",
       " 'pon',\n",
       " 'si',\n",
       " 'ble',\n",
       " '.',\n",
       " ' I',\n",
       " ' s',\n",
       " 'houl',\n",
       " 'd ',\n",
       " 'my',\n",
       " 'sel',\n",
       " 'f ',\n",
       " 'be ',\n",
       " 'gla',\n",
       " 'd ',\n",
       " 'to ',\n",
       " 'di',\n",
       " 'sow',\n",
       " 'n i',\n",
       " 't ',\n",
       " 'fo',\n",
       " 'r ',\n",
       " 'va',\n",
       " 'rio',\n",
       " 'u',\n",
       " 's ',\n",
       " 'rea',\n",
       " 'sons',\n",
       " ',',\n",
       " ' ',\n",
       " 'bu',\n",
       " 't t',\n",
       " 'hi',\n",
       " 's i',\n",
       " 's ',\n",
       " 'no',\n",
       " 't ',\n",
       " 'per',\n",
       " 'mit',\n",
       " 'ted',\n",
       " '.',\n",
       " ' I',\n",
       " ' ',\n",
       " 're',\n",
       " 'cei',\n",
       " 've ',\n",
       " 'mai',\n",
       " 'l ',\n",
       " 'fro',\n",
       " 'm s',\n",
       " 'tu',\n",
       " 'den',\n",
       " 'ts w',\n",
       " 'ho ',\n",
       " 'try ',\n",
       " 'to w',\n",
       " 'ri',\n",
       " 'te t',\n",
       " 'he',\n",
       " 'se',\n",
       " 's a',\n",
       " 'bou',\n",
       " 't i',\n",
       " 't o',\n",
       " 'r ',\n",
       " 're',\n",
       " 'ques',\n",
       " 'ts ',\n",
       " 'fro',\n",
       " 'm ',\n",
       " 'Ja',\n",
       " 'pa',\n",
       " 'ne',\n",
       " 'se ',\n",
       " 'dra',\n",
       " 'ma',\n",
       " 'tur',\n",
       " 'ge',\n",
       " 's ',\n",
       " 'to ',\n",
       " 'tur',\n",
       " 'n I',\n",
       " 't in',\n",
       " 'to ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'sor',\n",
       " 't o',\n",
       " 'f ',\n",
       " 'No',\n",
       " 'h ',\n",
       " 'play',\n",
       " '.',\n",
       " ' I',\n",
       " 't ',\n",
       " 'seem',\n",
       " 's ',\n",
       " 'li',\n",
       " 'ke',\n",
       " 'ly ',\n",
       " 'to ',\n",
       " 'sur',\n",
       " 'vi',\n",
       " 've',\n",
       " ',',\n",
       " ' w',\n",
       " 'hi',\n",
       " 'le ',\n",
       " 'ot',\n",
       " 'he',\n",
       " 'r ',\n",
       " 'wor',\n",
       " 'ks o',\n",
       " 'f ',\n",
       " 'mi',\n",
       " 'ne t',\n",
       " 'ha',\n",
       " 't I',\n",
       " ' ',\n",
       " 'va',\n",
       " 'lue',\n",
       " ' ',\n",
       " 'mo',\n",
       " 're ',\n",
       " 'bi',\n",
       " 'te t',\n",
       " 'he ',\n",
       " 'dust',\n",
       " '.',\n",
       " ' T',\n",
       " 'hi',\n",
       " 's i',\n",
       " 's ',\n",
       " 'no',\n",
       " 't a',\n",
       " 'n u',\n",
       " 'nu',\n",
       " 'sua',\n",
       " 'l ex',\n",
       " 'pe',\n",
       " 'rien',\n",
       " 'ce ',\n",
       " 'fo',\n",
       " 'r a',\n",
       " 'n ar',\n",
       " 'tist',\n",
       " '.',\n",
       " ' ',\n",
       " 'Rac',\n",
       " 'hma',\n",
       " 'ni',\n",
       " 'nof',\n",
       " 'f u',\n",
       " 'se',\n",
       " 'd ',\n",
       " 'to ',\n",
       " 'groa',\n",
       " 'n ',\n",
       " 'be',\n",
       " 'cau',\n",
       " 'se ',\n",
       " 'he ',\n",
       " 'wa',\n",
       " 's ',\n",
       " 'know',\n",
       " 'n ',\n",
       " 'main',\n",
       " 'ly ',\n",
       " 'fo',\n",
       " 'r a',\n",
       " ' ',\n",
       " 'Pre',\n",
       " 'lu',\n",
       " 'de ',\n",
       " 'i',\n",
       " 'n ',\n",
       " 'C S',\n",
       " 'har',\n",
       " 'p ',\n",
       " 'Mi',\n",
       " 'no',\n",
       " 'r w',\n",
       " 'hic',\n",
       " 'h ',\n",
       " 'he w',\n",
       " 'ro',\n",
       " 'te ',\n",
       " 'a',\n",
       " 's a',\n",
       " ' ',\n",
       " 'boy',\n",
       " ',',\n",
       " ' w',\n",
       " 'hi',\n",
       " 'le t',\n",
       " 'he ',\n",
       " 'wor',\n",
       " 'ks o',\n",
       " 'f ',\n",
       " 'hi',\n",
       " 's ',\n",
       " 'ma',\n",
       " 'tu',\n",
       " 'ri',\n",
       " 'ty ',\n",
       " 'ne',\n",
       " 've',\n",
       " 'r ',\n",
       " 'go',\n",
       " 't in',\n",
       " 'to t',\n",
       " 'he ',\n",
       " 'pro',\n",
       " 'gram',\n",
       " 'mes',\n",
       " '.',\n",
       " ' ',\n",
       " 'Ki',\n",
       " 'ds ',\n",
       " 'cu',\n",
       " 't t',\n",
       " 'hei',\n",
       " 'r ',\n",
       " 'pia',\n",
       " 'nis',\n",
       " 'ti',\n",
       " 'c ',\n",
       " 'teet',\n",
       " 'h o',\n",
       " 'n a',\n",
       " ' ',\n",
       " 'Mi',\n",
       " 'nue',\n",
       " 't i',\n",
       " 'n ',\n",
       " 'G w',\n",
       " 'hic',\n",
       " 'h ',\n",
       " 'Beet',\n",
       " 'ho',\n",
       " 've',\n",
       " 'n ',\n",
       " 'com',\n",
       " 'po',\n",
       " 'se',\n",
       " 'd on',\n",
       " 'ly ',\n",
       " 'so t',\n",
       " 'ha',\n",
       " 't ',\n",
       " 'he ',\n",
       " 'coul',\n",
       " 'd ',\n",
       " 'de',\n",
       " 'tes',\n",
       " 't it',\n",
       " '.',\n",
       " ' I',\n",
       " ' ',\n",
       " 'ha',\n",
       " 've ',\n",
       " 'to ',\n",
       " 'go ',\n",
       " 'o',\n",
       " 'n ',\n",
       " 'li',\n",
       " 'vin',\n",
       " 'g ',\n",
       " 'wit',\n",
       " 'h A',\n",
       " ' ',\n",
       " 'Cloc',\n",
       " 'kwor',\n",
       " 'k O',\n",
       " 'ran',\n",
       " 'ge',\n",
       " ',',\n",
       " ' an',\n",
       " 'd t',\n",
       " 'hi',\n",
       " 's ',\n",
       " 'mean',\n",
       " 's I',\n",
       " ' ',\n",
       " 'ha',\n",
       " 've ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'sor',\n",
       " 't o',\n",
       " 'f a',\n",
       " 'ut',\n",
       " 'ho',\n",
       " 'ria',\n",
       " 'l ',\n",
       " 'du',\n",
       " 'ty ',\n",
       " 'to ',\n",
       " 'it',\n",
       " '.',\n",
       " ' I',\n",
       " ' ',\n",
       " 'ha',\n",
       " 've ',\n",
       " 'a',\n",
       " ' ',\n",
       " 've',\n",
       " 'ry s',\n",
       " 'pe',\n",
       " 'cia',\n",
       " 'l ',\n",
       " 'du',\n",
       " 'ty ',\n",
       " 'to ',\n",
       " 'i',\n",
       " 't i',\n",
       " 'n t',\n",
       " 'he U',\n",
       " 'ni',\n",
       " 'te',\n",
       " 'd S',\n",
       " 'ta',\n",
       " 'tes',\n",
       " ',',\n",
       " ' an',\n",
       " 'd I',\n",
       " ' ',\n",
       " 'ha',\n",
       " 'd ',\n",
       " 'bet',\n",
       " 'te',\n",
       " 'r ',\n",
       " 'no',\n",
       " 'w ex',\n",
       " 'plai',\n",
       " 'n w',\n",
       " 'ha',\n",
       " 't t',\n",
       " 'hi',\n",
       " 's ',\n",
       " 'du',\n",
       " 'ty ',\n",
       " 'is',\n",
       " '.',\n",
       " ' ',\n",
       " 'Le',\n",
       " 't ',\n",
       " 'me ',\n",
       " 'pu',\n",
       " 't t',\n",
       " 'he ',\n",
       " 'si',\n",
       " 'tua',\n",
       " 'tio',\n",
       " 'n ',\n",
       " 'bal',\n",
       " 'dly',\n",
       " '.',\n",
       " ' A',\n",
       " ' ',\n",
       " 'Cloc',\n",
       " 'kwor',\n",
       " 'k O',\n",
       " 'ran',\n",
       " 'ge ',\n",
       " 'ha',\n",
       " 's ',\n",
       " 'ne',\n",
       " 've',\n",
       " 'r ',\n",
       " 'bee',\n",
       " 'n ',\n",
       " 'pu',\n",
       " 'blis',\n",
       " 'he',\n",
       " 'd en',\n",
       " 'ti',\n",
       " 're ',\n",
       " 'i',\n",
       " 'n A',\n",
       " 'me',\n",
       " 'ri',\n",
       " 'ca',\n",
       " '.',\n",
       " ' T',\n",
       " 'he ',\n",
       " 'boo',\n",
       " 'k I',\n",
       " ' w',\n",
       " 'ro',\n",
       " 'te ',\n",
       " 'i',\n",
       " 's ',\n",
       " 'di',\n",
       " 'vi',\n",
       " 'de',\n",
       " 'd in',\n",
       " 'to t',\n",
       " 'hree',\n",
       " ' ',\n",
       " 'sec',\n",
       " 'tion',\n",
       " 's o',\n",
       " 'f ',\n",
       " 'se',\n",
       " 've',\n",
       " 'n c',\n",
       " 'hap',\n",
       " 'ter',\n",
       " 's e',\n",
       " 'ach',\n",
       " '.',\n",
       " ' ',\n",
       " 'Ta',\n",
       " 'ke ',\n",
       " 'o',\n",
       " 'u',\n",
       " 't y',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r ',\n",
       " 'poc',\n",
       " 'ke',\n",
       " 't ',\n",
       " 'cal',\n",
       " 'cu',\n",
       " 'la',\n",
       " 'to',\n",
       " 'r an',\n",
       " 'd y',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'wil',\n",
       " 'l ',\n",
       " 'fin',\n",
       " 'd t',\n",
       " 'ha',\n",
       " 't t',\n",
       " 'he',\n",
       " 'se ',\n",
       " 'ad',\n",
       " 'd u',\n",
       " 'p ',\n",
       " 'to ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'to',\n",
       " 'ta',\n",
       " 'l o',\n",
       " 'f ',\n",
       " 'twen',\n",
       " 'ty',\n",
       " '-',\n",
       " 'o',\n",
       " 'ne c',\n",
       " 'hap',\n",
       " 'ters',\n",
       " '.',\n",
       " ' 2',\n",
       " '1',\n",
       " ' i',\n",
       " 's t',\n",
       " 'he ',\n",
       " 'sym',\n",
       " 'bo',\n",
       " 'l ',\n",
       " 'fo',\n",
       " 'r ',\n",
       " 'hu',\n",
       " 'ma',\n",
       " 'n ',\n",
       " 'ma',\n",
       " 'tu',\n",
       " 'ri',\n",
       " 'ty',\n",
       " ',',\n",
       " ' o',\n",
       " 'r u',\n",
       " 'se',\n",
       " 'd ',\n",
       " 'to ',\n",
       " 'be',\n",
       " ',',\n",
       " ' ',\n",
       " 'sin',\n",
       " 'ce ',\n",
       " 'a',\n",
       " 't 2',\n",
       " '1',\n",
       " ' y',\n",
       " 'o',\n",
       " 'u',\n",
       " ' ',\n",
       " 'go',\n",
       " 't t',\n",
       " 'he ',\n",
       " 'vo',\n",
       " 'te ',\n",
       " 'an',\n",
       " 'd as',\n",
       " 'su',\n",
       " 'me',\n",
       " 'd a',\n",
       " 'dul',\n",
       " 't ',\n",
       " 'res',\n",
       " 'pon',\n",
       " 'si',\n",
       " 'bi',\n",
       " 'li',\n",
       " 'ty',\n",
       " '.',\n",
       " ' W',\n",
       " 'ha',\n",
       " 'te',\n",
       " 've',\n",
       " 'r i',\n",
       " 'ts ',\n",
       " 'sym',\n",
       " 'bo',\n",
       " 'lo',\n",
       " 'gy',\n",
       " ',',\n",
       " ' t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r 2',\n",
       " '1',\n",
       " ' ',\n",
       " 'wa',\n",
       " 's t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r I',\n",
       " ' s',\n",
       " 'tar',\n",
       " 'te',\n",
       " 'd o',\n",
       " 'u',\n",
       " 't ',\n",
       " 'with',\n",
       " '.',\n",
       " ' ',\n",
       " 'No',\n",
       " 've',\n",
       " 'lis',\n",
       " 'ts o',\n",
       " 'f ',\n",
       " 'my s',\n",
       " 'tam',\n",
       " 'p a',\n",
       " 're ',\n",
       " 'in',\n",
       " 'te',\n",
       " 'res',\n",
       " 'te',\n",
       " 'd i',\n",
       " 'n w',\n",
       " 'ha',\n",
       " 't i',\n",
       " 's ',\n",
       " 'cal',\n",
       " 'le',\n",
       " 'd a',\n",
       " 'rit',\n",
       " 'hmo',\n",
       " 'lo',\n",
       " 'gy',\n",
       " ',',\n",
       " ' ',\n",
       " 'mea',\n",
       " 'nin',\n",
       " 'g t',\n",
       " 'ha',\n",
       " 't ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r ',\n",
       " 'ha',\n",
       " 's ',\n",
       " 'to ',\n",
       " 'mea',\n",
       " 'n ',\n",
       " 'so',\n",
       " 'met',\n",
       " 'hin',\n",
       " 'g i',\n",
       " 'n ',\n",
       " 'hu',\n",
       " 'ma',\n",
       " 'n ',\n",
       " 'term',\n",
       " 's w',\n",
       " 'he',\n",
       " 'n t',\n",
       " 'hey',\n",
       " ' ',\n",
       " 'han',\n",
       " 'dle ',\n",
       " 'it',\n",
       " '.',\n",
       " ' T',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r o',\n",
       " 'f c',\n",
       " 'hap',\n",
       " 'ter',\n",
       " 's i',\n",
       " 's ',\n",
       " 'ne',\n",
       " 've',\n",
       " 'r en',\n",
       " 'ti',\n",
       " 're',\n",
       " 'ly ',\n",
       " 'ar',\n",
       " 'bi',\n",
       " 'tra',\n",
       " 'ry',\n",
       " '.',\n",
       " ' ',\n",
       " 'Jus',\n",
       " 't a',\n",
       " 's a',\n",
       " ' ',\n",
       " 'mu',\n",
       " 'si',\n",
       " 'ca',\n",
       " 'l ',\n",
       " 'com',\n",
       " 'po',\n",
       " 'se',\n",
       " 'r s',\n",
       " 'tar',\n",
       " 'ts of',\n",
       " 'f ',\n",
       " 'wit',\n",
       " 'h a',\n",
       " ' ',\n",
       " 'va',\n",
       " 'gue',\n",
       " ' ',\n",
       " 'i',\n",
       " 'ma',\n",
       " 'ge ',\n",
       " 'o',\n",
       " 'f ',\n",
       " 'bul',\n",
       " 'k an',\n",
       " 'd ',\n",
       " 'du',\n",
       " 'ra',\n",
       " 'tion',\n",
       " ',',\n",
       " ' ',\n",
       " 'so ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'no',\n",
       " 've',\n",
       " 'lis',\n",
       " 't ',\n",
       " 'be',\n",
       " 'gin',\n",
       " 's ',\n",
       " 'wit',\n",
       " 'h a',\n",
       " 'n i',\n",
       " 'ma',\n",
       " 'ge ',\n",
       " 'o',\n",
       " 'f ',\n",
       " 'length',\n",
       " ',',\n",
       " ' an',\n",
       " 'd t',\n",
       " 'hi',\n",
       " 's i',\n",
       " 'ma',\n",
       " 'ge ',\n",
       " 'i',\n",
       " 's ex',\n",
       " 'pres',\n",
       " 'se',\n",
       " 'd i',\n",
       " 'n t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r o',\n",
       " 'f ',\n",
       " 'sec',\n",
       " 'tion',\n",
       " 's an',\n",
       " 'd t',\n",
       " 'he ',\n",
       " 'num',\n",
       " 'be',\n",
       " 'r o',\n",
       " 'f c',\n",
       " 'hap',\n",
       " 'ter',\n",
       " 's i',\n",
       " 'n w',\n",
       " 'hic',\n",
       " 'h t',\n",
       " 'he ',\n",
       " 'wor',\n",
       " 'k ',\n",
       " 'wil',\n",
       " 'l ',\n",
       " 'be ',\n",
       " 'dis',\n",
       " 'po',\n",
       " 'sed',\n",
       " '.',\n",
       " ' T',\n",
       " 'ho',\n",
       " 'se ',\n",
       " 'twen',\n",
       " 'ty',\n",
       " '-',\n",
       " 'o',\n",
       " 'ne c',\n",
       " 'hap',\n",
       " 'ter',\n",
       " 's ',\n",
       " 'we',\n",
       " 're ',\n",
       " 'im',\n",
       " 'por',\n",
       " 'tan',\n",
       " 't ',\n",
       " 'to ',\n",
       " 'me',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.SyllableTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TabTokenizer -- делит текст по табуляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = nt.TabTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\asdsf\\major-IT-musled\\tokerize\\tokenize.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m stopwords (\u001b[39mlist\u001b[39;49m(\u001b[39mstr\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m w \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/asdsf/major-IT-musled/tokerize/tokenize.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords (list(str))\n",
    "w = 10\n",
    "k = 5\n",
    "tk = nt.TextTilingTokenizer(w, k, stopwords)\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TokTokTokenizer - получает на вход предложение и возвращает слово как токен. Рекомендуется проверять и дополнительно очищать текст после применения ToktokTokenizer, например, от знаков препинания и иных символов – бывает, что они «приклеиваются» к словам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'\",\n",
       " 's',\n",
       " 'literary',\n",
       " 'memory.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " 'chapters.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed.',\n",
       " 'Those',\n",
       " 'twenty-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.ToktokTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Этот токенизатор выполняет следующие шаги: \n",
    "\n",
    "    - разделяет стандартные сокращения, например ``don't`` -> ``do n 't`` и ``they'll`` -> ``they 'll`` \n",
    "    - большинство знаков препинания рассматриваются как отдельные токены \n",
    "    - отделяются запятые и одинарные кавычки, если за ними следуют пробелы \n",
    "    - отдельные точки, которые появляются в конце line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I   f i r s t   p u b l i s h e d   t h e   n o v e l l a   A   C l o c k w o r k   O r a n g e   i n   1 9 6 2,   w h i c h   o u g h t   t o   b e   f a r   e n o u g h   i n   t h e   p a s t   f o r   i t   t o   b e   e r a s e d   f r o m   t h e   w o r l d' s   l i t e r a r y   m e m o r y .   I t   r e f u s e s   t o   b e   e r a s e d,   h o w e v e r,   a n d   f o r   t h i s   t h e   f i l m   v e r s i o n   o f   t h e   b o o k   m a d e   b y   S t a n l e y   K u b r i c k   m a y   b e   h e l d   c h i e f l y   r e s p o n s i b l e .   I   s h o u l d   m y s e l f   b e   g l a d   t o   d i s o w n   i t   f o r   v a r i o u s   r e a s o n s,   b u t   t h i s   i s   n o t   p e r m i t t e d .   I   r e c e i v e   m a i l   f r o m   s t u d e n t s   w h o   t r y   t o   w r i t e   t h e s e s   a b o u t   i t   o r   r e q u e s t s   f r o m   J a p a n e s e   d r a m a t u r g e s   t o   t u r n   I t   i n t o   a   s o r t   o f   N o h   p l a y .   I t   s e e m s   l i k e l y   t o   s u r v i v e,   w h i l e   o t h e r   w o r k s   o f   m i n e   t h a t   I   v a l u e   m o r e   b i t e   t h e   d u s t .   T h i s   i s   n o t   a n   u n u s u a l   e x p e r i e n c e   f o r   a n   a r t i s t .   R a c h m a n i n o f f   u s e d   t o   g r o a n   b e c a u s e   h e   w a s   k n o w n   m a i n l y   f o r   a   P r e l u d e   i n   C   S h a r p   M i n o r   w h i c h   h e   w r o t e   a s   a   b o y,   w h i l e   t h e   w o r k s   o f   h i s   m a t u r i t y   n e v e r   g o t   i n t o   t h e   p r o g r a m m e s .   K i d s   c u t   t h e i r   p i a n i s t i c   t e e t h   o n   a   M i n u e t   i n   G   w h i c h   B e e t h o v e n   c o m p o s e d   o n l y   s o   t h a t   h e   c o u l d   d e t e s t   i t .   I   h a v e   t o   g o   o n   l i v i n g   w i t h   A   C l o c k w o r k   O r a n g e,   a n d   t h i s   m e a n s   I   h a v e   a   s o r t   o f   a u t h o r i a l   d u t y   t o   i t .   I   h a v e   a   v e r y   s p e c i a l   d u t y   t o   i t   i n   t h e   U n i t e d   S t a t e s,   a n d   I   h a d   b e t t e r   n o w   e x p l a i n   w h a t   t h i s   d u t y   i s .   L e t   m e   p u t   t h e   s i t u a t i o n   b a l d l y .   A   C l o c k w o r k   O r a n g e   h a s   n e v e r   b e e n   p u b l i s h e d   e n t i r e   i n   A m e r i c a .   T h e   b o o k   I   w r o t e   i s   d i v i d e d   i n t o   t h r e e   s e c t i o n s   o f   s e v e n   c h a p t e r s   e a c h .   T a k e   o u t   y o u r   p o c k e t   c a l c u l a t o r   a n d   y o u   w i l l   f i n d   t h a t   t h e s e   a d d   u p   t o   a   t o t a l   o f   t w e n t y - o n e   c h a p t e r s .   2 1   i s   t h e   s y m b o l   f o r   h u m a n   m a t u r i t y,   o r   u s e d   t o   b e,   s i n c e   a t   2 1   y o u   g o t   t h e   v o t e   a n d   a s s u m e d   a d u l t   r e s p o n s i b i l i t y .   W h a t e v e r   i t s   s y m b o l o g y,   t h e   n u m b e r   2 1   w a s   t h e   n u m b e r   I   s t a r t e d   o u t   w i t h .   N o v e l i s t s   o f   m y   s t a m p   a r e   i n t e r e s t e d   i n   w h a t   i s   c a l l e d   a r i t h m o l o g y,   m e a n i n g   t h a t   n u m b e r   h a s   t o   m e a n   s o m e t h i n g   i n   h u m a n   t e r m s   w h e n   t h e y   h a n d l e   i t .   T h e   n u m b e r   o f   c h a p t e r s   i s   n e v e r   e n t i r e l y   a r b i t r a r y .   J u s t   a s   a   m u s i c a l   c o m p o s e r   s t a r t s   o f f   w i t h   a   v a g u e   i m a g e   o f   b u l k   a n d   d u r a t i o n,   s o   a   n o v e l i s t   b e g i n s   w i t h   a n   i m a g e   o f   l e n g t h,   a n d   t h i s   i m a g e   i s   e x p r e s s e d   i n   t h e   n u m b e r   o f   s e c t i o n s   a n d   t h e   n u m b e r   o f   c h a p t e r s   i n   w h i c h   t h e   w o r k   w i l l   b e   d i s p o s e d .   T h o s e   t w e n t y - o n e   c h a p t e r s   w e r e   i m p o r t a n t   t o   m e.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.TreebankWordDetokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Этот токенизатор выполняет следующие шаги: \n",
    "\n",
    "    - разделяет стандартные сокращения, например ``don't`` -> ``do n 't`` и ``they'll`` -> ``they 'll`` \n",
    "    - большинство знаков препинания рассматриваются как отдельные токены \n",
    "    - отделяются запятые и одинарные кавычки, если за ними следуют пробелы \n",
    "    - отдельные точки, которые появляются в конце line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'literary',\n",
       " 'memory.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " 'chapters.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed.',\n",
       " 'Those',\n",
       " 'twenty-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.TreebankWordTokenizer()\n",
    "\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Может токенезировать хештеги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Looking', 'forward', 'to', 'the', 'weekend', '!', '#excited']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.TweetTokenizer()\n",
    "tweet = \"Looking forward to the weekend! #excited\"\n",
    "tk.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962,',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " \"world's\",\n",
       " 'literary',\n",
       " 'memory.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased,',\n",
       " 'however,',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons,',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive,',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy,',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange,',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty-one',\n",
       " 'chapters.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity,',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be,',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology,',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology,',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration,',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length,',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed.',\n",
       " 'Those',\n",
       " 'twenty-one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.WhitespaceTokenizer()\n",
    "tk. tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'\",\n",
       " 's',\n",
       " 'literary',\n",
       " 'memory',\n",
       " '.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted',\n",
       " '.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play',\n",
       " '.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist',\n",
       " '.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes',\n",
       " '.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is',\n",
       " '.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly',\n",
       " '.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America',\n",
       " '.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each',\n",
       " '.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'chapters',\n",
       " '.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility',\n",
       " '.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with',\n",
       " '.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it',\n",
       " '.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed',\n",
       " '.',\n",
       " 'Those',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = nt.WordPunctTokenizer()\n",
    "tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp310-cp310-win_amd64.whl (12.1 MB)\n",
      "     ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/12.1 MB 1.3 MB/s eta 0:00:10\n",
      "      --------------------------------------- 0.2/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.3/12.1 MB 1.9 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.4/12.1 MB 1.9 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.6/12.1 MB 2.1 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/12.1 MB 2.7 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.0/12.1 MB 2.7 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.3/12.1 MB 3.1 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.4/12.1 MB 3.1 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.6/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.8/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 1.9/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.1/12.1 MB 3.3 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.2/12.1 MB 3.2 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.1 MB 3.5 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.8/12.1 MB 3.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.1/12.1 MB 3.7 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.5/12.1 MB 4.0 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.0/12.1 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.0/12.1 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.3/12.1 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.3/12.1 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.4/12.1 MB 3.8 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.3/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.5/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.7/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.7/12.1 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 5.7/12.1 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.5/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 6.8/12.1 MB 4.5 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.1/12.1 MB 4.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.4/12.1 MB 4.7 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 7.7/12.1 MB 4.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.1/12.1 MB 4.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.3/12.1 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 8.7/12.1 MB 4.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.0/12.1 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.3/12.1 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 9.7/12.1 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 9.9/12.1 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.2/12.1 MB 5.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 10.6/12.1 MB 5.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 10.8/12.1 MB 5.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.2/12.1 MB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 11.5/12.1 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 11.7/12.1 MB 5.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.1/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.1/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.1/12.1 MB 5.7 MB/s eta 0:00:00\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 0.0/49.8 kB ? eta -:--:--\n",
      "     -------------------------------- ------- 41.0/49.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 49.8/49.8 kB 638.5 kB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp310-cp310-win_amd64.whl (122 kB)\n",
      "     ---------------------------------------- 0.0/122.2 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 112.6/122.2 kB 6.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 112.6/122.2 kB 6.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 122.2/122.2 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     ------------------------------------ - 174.1/181.6 kB 3.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 181.6/181.6 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-win_amd64.whl (25 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (2.31.0)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 41.0/57.0 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------------- --- 51.2/57.0 kB 890.4 kB/s eta 0:00:01\n",
      "     ---------------------------------- --- 51.2/57.0 kB 890.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.0/57.0 kB 374.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (4.66.1)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from spacy) (23.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Downloading thinc-8.2.1-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.2/1.5 MB 6.9 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 0.3/1.5 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.2/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.3/1.5 MB 7.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "     ---------------------------------------- 0.0/395.8 kB ? eta -:--:--\n",
      "     ---------------------------------------  389.1/395.8 kB ? eta -:--:--\n",
      "     ---------------------------------------  389.1/395.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 395.8/395.8 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp310-cp310-win_amd64.whl (481 kB)\n",
      "     ---------------------------------------- 0.0/481.9 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 194.6/481.9 kB ? eta -:--:--\n",
      "     ---------------------------- --------- 358.4/481.9 kB 7.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  481.3/481.9 kB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------------------  481.3/481.9 kB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 481.9/481.9 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 41.0/45.9 kB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 41.0/45.9 kB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 45.9/45.9 kB 323.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Collecting pydantic-core==2.10.1\n",
      "  Downloading pydantic_core-2.10.1-cp310-none-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.2/2.0 MB 10.9 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 0.5/2.0 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 0.7/2.0 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.0/2.0 MB 4.8 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/2.0 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 1.5/2.0 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.8/2.0 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.0 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.0/2.0 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.0/2.0 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.5/6.6 MB 7.1 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.7/6.6 MB 6.7 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.0/6.6 MB 6.4 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.4/6.6 MB 5.7 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.5/6.6 MB 5.1 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 1.8/6.6 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.2/6.6 MB 5.5 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.4/6.6 MB 5.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 2.9/6.6 MB 5.5 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.1/6.6 MB 5.4 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.5/6.6 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 3.7/6.6 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.1/6.6 MB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.5/6.6 MB 5.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.8/6.6 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 5.3/6.6 MB 5.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.6/6.6 MB 5.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.9/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.3/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.6/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.6/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.6/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.6/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  6.6/6.6 MB 6.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.6/6.6 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\asdsf\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 41.0/45.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 45.0/45.0 kB 740.0 kB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic-core, murmurhash, MarkupSafe, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic, preshed, jinja2, confection, weasel, thinc, spacy\n",
      "Successfully installed MarkupSafe-2.1.3 annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.3 cymem-2.0.8 jinja2-3.1.2 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.4.2 pydantic-core-2.10.1 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 typer-0.9.0 wasabi-1.1.2 weasel-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\asdsf\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as s \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот токенатор принимает за токены не только слова, но и знаки припинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'I',\n",
       " 'first',\n",
       " 'published',\n",
       " 'the',\n",
       " 'novella',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'in',\n",
       " '1962',\n",
       " ',',\n",
       " 'which',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'be',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " 'from',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'literary',\n",
       " 'memory',\n",
       " '.',\n",
       " 'It',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'erased',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'and',\n",
       " 'for',\n",
       " 'this',\n",
       " 'the',\n",
       " 'film',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'book',\n",
       " 'made',\n",
       " 'by',\n",
       " 'Stanley',\n",
       " 'Kubrick',\n",
       " 'may',\n",
       " 'be',\n",
       " 'held',\n",
       " 'chiefly',\n",
       " 'responsible',\n",
       " '.',\n",
       " 'I',\n",
       " 'should',\n",
       " 'myself',\n",
       " 'be',\n",
       " 'glad',\n",
       " 'to',\n",
       " 'disown',\n",
       " 'it',\n",
       " 'for',\n",
       " 'various',\n",
       " 'reasons',\n",
       " ',',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'permitted',\n",
       " '.',\n",
       " 'I',\n",
       " 'receive',\n",
       " 'mail',\n",
       " 'from',\n",
       " 'students',\n",
       " 'who',\n",
       " 'try',\n",
       " 'to',\n",
       " 'write',\n",
       " 'theses',\n",
       " 'about',\n",
       " 'it',\n",
       " 'or',\n",
       " 'requests',\n",
       " 'from',\n",
       " 'Japanese',\n",
       " 'dramaturges',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'It',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'Noh',\n",
       " 'play',\n",
       " '.',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'survive',\n",
       " ',',\n",
       " 'while',\n",
       " 'other',\n",
       " 'works',\n",
       " 'of',\n",
       " 'mine',\n",
       " 'that',\n",
       " 'I',\n",
       " 'value',\n",
       " 'more',\n",
       " 'bite',\n",
       " 'the',\n",
       " 'dust',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'unusual',\n",
       " 'experience',\n",
       " 'for',\n",
       " 'an',\n",
       " 'artist',\n",
       " '.',\n",
       " 'Rachmaninoff',\n",
       " 'used',\n",
       " 'to',\n",
       " 'groan',\n",
       " 'because',\n",
       " 'he',\n",
       " 'was',\n",
       " 'known',\n",
       " 'mainly',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Prelude',\n",
       " 'in',\n",
       " 'C',\n",
       " 'Sharp',\n",
       " 'Minor',\n",
       " 'which',\n",
       " 'he',\n",
       " 'wrote',\n",
       " 'as',\n",
       " 'a',\n",
       " 'boy',\n",
       " ',',\n",
       " 'while',\n",
       " 'the',\n",
       " 'works',\n",
       " 'of',\n",
       " 'his',\n",
       " 'maturity',\n",
       " 'never',\n",
       " 'got',\n",
       " 'into',\n",
       " 'the',\n",
       " 'programmes',\n",
       " '.',\n",
       " 'Kids',\n",
       " 'cut',\n",
       " 'their',\n",
       " 'pianistic',\n",
       " 'teeth',\n",
       " 'on',\n",
       " 'a',\n",
       " 'Minuet',\n",
       " 'in',\n",
       " 'G',\n",
       " 'which',\n",
       " 'Beethoven',\n",
       " 'composed',\n",
       " 'only',\n",
       " 'so',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'detest',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'living',\n",
       " 'with',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'means',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'authorial',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'a',\n",
       " 'very',\n",
       " 'special',\n",
       " 'duty',\n",
       " 'to',\n",
       " 'it',\n",
       " 'in',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'had',\n",
       " 'better',\n",
       " 'now',\n",
       " 'explain',\n",
       " 'what',\n",
       " 'this',\n",
       " 'duty',\n",
       " 'is',\n",
       " '.',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'put',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'baldly',\n",
       " '.',\n",
       " 'A',\n",
       " 'Clockwork',\n",
       " 'Orange',\n",
       " 'has',\n",
       " 'never',\n",
       " 'been',\n",
       " 'published',\n",
       " 'entire',\n",
       " 'in',\n",
       " 'America',\n",
       " '.',\n",
       " 'The',\n",
       " 'book',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'is',\n",
       " 'divided',\n",
       " 'into',\n",
       " 'three',\n",
       " 'sections',\n",
       " 'of',\n",
       " 'seven',\n",
       " 'chapters',\n",
       " 'each',\n",
       " '.',\n",
       " 'Take',\n",
       " 'out',\n",
       " 'your',\n",
       " 'pocket',\n",
       " 'calculator',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'that',\n",
       " 'these',\n",
       " 'add',\n",
       " 'up',\n",
       " 'to',\n",
       " 'a',\n",
       " 'total',\n",
       " 'of',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'chapters',\n",
       " '.',\n",
       " '21',\n",
       " 'is',\n",
       " 'the',\n",
       " 'symbol',\n",
       " 'for',\n",
       " 'human',\n",
       " 'maturity',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'to',\n",
       " 'be',\n",
       " ',',\n",
       " 'since',\n",
       " 'at',\n",
       " '21',\n",
       " 'you',\n",
       " 'got',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'and',\n",
       " 'assumed',\n",
       " 'adult',\n",
       " 'responsibility',\n",
       " '.',\n",
       " 'Whatever',\n",
       " 'its',\n",
       " 'symbology',\n",
       " ',',\n",
       " 'the',\n",
       " 'number',\n",
       " '21',\n",
       " 'was',\n",
       " 'the',\n",
       " 'number',\n",
       " 'I',\n",
       " 'started',\n",
       " 'out',\n",
       " 'with',\n",
       " '.',\n",
       " 'Novelists',\n",
       " 'of',\n",
       " 'my',\n",
       " 'stamp',\n",
       " 'are',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'what',\n",
       " 'is',\n",
       " 'called',\n",
       " 'arithmology',\n",
       " ',',\n",
       " 'meaning',\n",
       " 'that',\n",
       " 'number',\n",
       " 'has',\n",
       " 'to',\n",
       " 'mean',\n",
       " 'something',\n",
       " 'in',\n",
       " 'human',\n",
       " 'terms',\n",
       " 'when',\n",
       " 'they',\n",
       " 'handle',\n",
       " 'it',\n",
       " '.',\n",
       " 'The',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'is',\n",
       " 'never',\n",
       " 'entirely',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " 'Just',\n",
       " 'as',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'composer',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'vague',\n",
       " 'image',\n",
       " 'of',\n",
       " 'bulk',\n",
       " 'and',\n",
       " 'duration',\n",
       " ',',\n",
       " 'so',\n",
       " 'a',\n",
       " 'novelist',\n",
       " 'begins',\n",
       " 'with',\n",
       " 'an',\n",
       " 'image',\n",
       " 'of',\n",
       " 'length',\n",
       " ',',\n",
       " 'and',\n",
       " 'this',\n",
       " 'image',\n",
       " 'is',\n",
       " 'expressed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sections',\n",
       " 'and',\n",
       " 'the',\n",
       " 'number',\n",
       " 'of',\n",
       " 'chapters',\n",
       " 'in',\n",
       " 'which',\n",
       " 'the',\n",
       " 'work',\n",
       " 'will',\n",
       " 'be',\n",
       " 'disposed',\n",
       " '.',\n",
       " 'Those',\n",
       " 'twenty',\n",
       " '-',\n",
       " 'one',\n",
       " 'chapters',\n",
       " 'were',\n",
       " 'important',\n",
       " 'to',\n",
       " 'me',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(s)\n",
    "model = s.load(\"en_core_web_sm\")\n",
    "book = model(text)\n",
    "tokens = [token.text for token in book]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лексическое разнообразия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10\n",
      "first 1\n",
      "published 2\n",
      "the 17\n",
      "novella 1\n",
      "A 3\n",
      "Clockwork 3\n",
      "Orange 3\n",
      "in 10\n",
      "1962 1\n",
      ", 14\n",
      "which 4\n",
      "ought 1\n",
      "to 15\n",
      "be 7\n",
      "far 1\n",
      "enough 1\n",
      "past 1\n",
      "for 6\n",
      "it 4\n",
      "erased 2\n",
      "from 3\n",
      "world 1\n",
      "' 1\n",
      "s 1\n",
      "literary 1\n",
      "memory. 1\n",
      "It 3\n",
      "refuses 1\n",
      "however 1\n",
      "and 8\n",
      "this 5\n",
      "film 1\n",
      "version 1\n",
      "of 13\n",
      "book 2\n",
      "made 1\n",
      "by 1\n",
      "Stanley 1\n",
      "Kubrick 1\n",
      "may 1\n",
      "held 1\n",
      "chiefly 1\n",
      "responsible. 1\n",
      "should 1\n",
      "myself 1\n",
      "glad 1\n",
      "disown 1\n",
      "various 1\n",
      "reasons 1\n",
      "but 1\n",
      "is 7\n",
      "not 2\n",
      "permitted. 1\n",
      "receive 1\n",
      "mail 1\n",
      "students 1\n",
      "who 1\n",
      "try 1\n",
      "write 1\n",
      "theses 1\n",
      "about 1\n",
      "or 2\n",
      "requests 1\n",
      "Japanese 1\n",
      "dramaturges 1\n",
      "turn 1\n",
      "into 3\n",
      "a 10\n",
      "sort 2\n",
      "Noh 1\n",
      "play. 1\n",
      "seems 1\n",
      "likely 1\n",
      "survive 1\n",
      "while 2\n",
      "other 1\n",
      "works 2\n",
      "mine 1\n",
      "that 4\n",
      "value 1\n",
      "more 1\n",
      "bite 1\n",
      "dust. 1\n",
      "This 1\n",
      "an 3\n",
      "unusual 1\n",
      "experience 1\n",
      "artist. 1\n",
      "Rachmaninoff 1\n",
      "used 2\n",
      "groan 1\n",
      "because 1\n",
      "he 3\n",
      "was 2\n",
      "known 1\n",
      "mainly 1\n",
      "Prelude 1\n",
      "C 1\n",
      "Sharp 1\n",
      "Minor 1\n",
      "wrote 2\n",
      "as 2\n",
      "boy 1\n",
      "his 1\n",
      "maturity 2\n",
      "never 3\n",
      "got 2\n",
      "programmes. 1\n",
      "Kids 1\n",
      "cut 1\n",
      "their 1\n",
      "pianistic 1\n",
      "teeth 1\n",
      "on 2\n",
      "Minuet 1\n",
      "G 1\n",
      "Beethoven 1\n",
      "composed 1\n",
      "only 1\n",
      "so 2\n",
      "could 1\n",
      "detest 1\n",
      "it. 3\n",
      "have 3\n",
      "go 1\n",
      "living 1\n",
      "with 3\n",
      "means 1\n",
      "authorial 1\n",
      "duty 3\n",
      "very 1\n",
      "special 1\n",
      "United 1\n",
      "States 1\n",
      "had 1\n",
      "better 1\n",
      "now 1\n",
      "explain 1\n",
      "what 2\n",
      "is. 1\n",
      "Let 1\n",
      "me 2\n",
      "put 1\n",
      "situation 1\n",
      "baldly. 1\n",
      "has 2\n",
      "been 1\n",
      "entire 1\n",
      "America. 1\n",
      "The 2\n",
      "divided 1\n",
      "three 1\n",
      "sections 2\n",
      "seven 1\n",
      "chapters 4\n",
      "each. 1\n",
      "Take 1\n",
      "out 2\n",
      "your 1\n",
      "pocket 1\n",
      "calculator 1\n",
      "you 2\n",
      "will 2\n",
      "find 1\n",
      "these 1\n",
      "add 1\n",
      "up 1\n",
      "total 1\n",
      "twenty-one 2\n",
      "chapters. 1\n",
      "21 3\n",
      "symbol 1\n",
      "human 2\n",
      "since 1\n",
      "at 1\n",
      "vote 1\n",
      "assumed 1\n",
      "adult 1\n",
      "responsibility. 1\n",
      "Whatever 1\n",
      "its 1\n",
      "symbology 1\n",
      "number 6\n",
      "started 1\n",
      "with. 1\n",
      "Novelists 1\n",
      "my 1\n",
      "stamp 1\n",
      "are 1\n",
      "interested 1\n",
      "called 1\n",
      "arithmology 1\n",
      "meaning 1\n",
      "mean 1\n",
      "something 1\n",
      "terms 1\n",
      "when 1\n",
      "they 1\n",
      "handle 1\n",
      "entirely 1\n",
      "arbitrary. 1\n",
      "Just 1\n",
      "musical 1\n",
      "composer 1\n",
      "starts 1\n",
      "off 1\n",
      "vague 1\n",
      "image 3\n",
      "bulk 1\n",
      "duration 1\n",
      "novelist 1\n",
      "begins 1\n",
      "length 1\n",
      "expressed 1\n",
      "work 1\n",
      "disposed. 1\n",
      "Those 1\n",
      "were 1\n",
      "important 1\n",
      ". 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "with open('book.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "word_counts = Counter(tokens)\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мой Б̶е̶к̶о̶н̶а̶т̶о̶р̶  токенатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r498rei', '438y', '504y98', '0', '3y40', '043']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        tokens = re.findall(r'\\w+', text.lower())\n",
    "        return tokens\n",
    "\n",
    "   \n",
    "\n",
    "t = Tokenizer()\n",
    "text = 'r498rei 438y 504y98 0 3y40 043'\n",
    "print(t.tokenize(text))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
